{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Projects in Advanced Machine Learning**"
      ],
      "metadata": {
        "id": "xFUCof9mHuCS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This portfolio contains 3 advanced machine learning projects that demonstrate a range of skills and techniques in the field of data science learned from QMSS 5074: Projects in Advanced Machine Learning, Spring 2023. The projects include:\n",
        "1. Report on U.N. World Happiness Data\n",
        "2. X-Ray Lung Image Analysis for COVID-19 Detection\n",
        "3. Predictive Model for Movie Review Classification\n",
        "\n",
        "The description of these projects and their Github links can be found below."
      ],
      "metadata": {
        "id": "5_HRl1OsH4rw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Report on U.N. World Happiness Data**\n",
        "\n",
        "**Github link: https://github.com/stellamym/Projects-AdvancedML/blob/main/Report%20on%20U.N.%20World%20Happiness%20DataMa.ipynb**\n",
        "\n",
        "The United Nations World Happiness Report is an annual publication that measures the happiness of people around the world. The report analyzes a range of factors that contribute to happiness, including economic, social, and environmental factors. Analyzing the UN World Happiness Data can provide valuable insights into the factors that contribute to happiness and well-being around the world. Here are some reasons why we should analyze this data:\n",
        "\n",
        "1. Understanding happiness: The UN World Happiness Data can help us understand what makes people happy and what factors contribute to their overall well-being. This can help policymakers and governments to design policies that promote happiness and well-being.\n",
        "\n",
        "2. Identifying trends: By analyzing the data over time, we can identify trends and changes in happiness levels across different countries and regions. This can help us to understand how global events and changes in policies are affecting people's happiness and well-being.\n",
        "\n",
        "3. Comparing countries: The UN World Happiness Data allows us to compare the happiness levels of different countries and regions, providing insights into the factors that contribute to happiness and well-being in different parts of the world.\n",
        "\n",
        "4. Developing interventions: Analyzing the data can help us to identify areas where interventions can be made to improve happiness and well-being. For example, if a particular factor is found to be negatively impacting happiness levels in a country, policymakers can work to address that factor to improve overall well-being.\n",
        "\n",
        "5. Promoting well-being: Analyzing the data can help to promote well-being by providing evidence-based insights into the factors that contribute to happiness. This can help individuals, organizations, and governments to make informed decisions that promote happiness and well-being.\n",
        "\n",
        "Overall, analyzing the UN World Happiness Data can provide valuable insights into the factors that contribute to happiness and well-being around the world. The data can be used to inform policy decisions, develop interventions to improve well-being, and promote happiness and well-being globally.\n",
        "\n",
        "The dataset I used in this project is retrieved from WHR 2022 | CHAPTER 2\n",
        "Happiness, Benevolence, and Trust During COVID-19 and Beyond. \n",
        "1. X_train: there are 88 countries data, each country has 10 features, including GDP per capita, Social support, Healthy life expectancy, Freedom to make life choices, Generosity, Perceptions of corruption, name, region, sub-region, and Terrorist-attacks.\n",
        "2. X_test: there are 68 countries data, each country has 10 features, including GDP per capita, Social support, Healthy life expectancy, Freedom to make life choices, Generosity, Perceptions of corruption, name, region, sub-region, and Terrorist-attacks.\n",
        "3. y_train: there are 88 rows of data, showing the level of happiness with five dummy variables: average, low, high, very high, and very low.\n",
        "\n",
        "Before I start with the modeling, I explore the bivariate result and plot some visualizations. I find that that there is a positive relation between Social Support and Happiness Level. The more social support, the higher happiness level.\n",
        "\n",
        "I tried 3 models in total. The first two models use Random Forest Classifier, and the third model uses Logistic Regression. Among them, the best model is model 2, a random forest classifier with n_estimator=1000. "
      ],
      "metadata": {
        "id": "yvcdRl2KH4ph"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. X-Ray Lung Image Analysis for COVID-19 Detection**\n",
        "\n",
        "**Github link: https://github.com/stellamym/Projects-AdvancedML/blob/main/X-Ray%20Lung%20Image%20Analysis%20for%20COVID-19%20Detection.ipynb**\n",
        "\n",
        "This project aims to build models to predict the symptom of X-Ray lung image. Starting from 2020, COVID-19 has had a profound impact on the world, affecting nearly every aspect of daily life. The pandemic has caused widespread illness and death, disrupted economies, strained healthcare systems, and forced people to adapt to new ways of working, learning, and socializing.\n",
        "\n",
        "The dataset I use covers three categories of lung X-Ray images: NORMAL, COVID, and PNEUMONIA. \n",
        "\n",
        "*   NORMAL: X-Ray image of normal lung.\n",
        "*   COVID: X-Ray image of lung with COVID positive.\n",
        "*   PNEUMONIA: X-Ray image of lung with viral Pneumonia.\n",
        "\n",
        "The raw dataset covers: 3616 COVID images, 10192 NORMAL images, 1345 VIRAL PNEUMONIA images. \n",
        "\n",
        "In this project, we preprocess the dataset and manage into a new dataset with 4032 images. For each of the three category, we cover 1344 images.\n",
        "\n",
        "The preprocessed dataset covers: 1344 COVID images, 1344 NORMAL images, 1344 VIRAL PNEUMONIA images. \n",
        "\n",
        "I tried 5 models in total. All the five models are TensorFlow Keras Sequential model that defines a convolutional neural network (CNN) architecture for 3-class image classification. The first three models are first created and compared. Among them, the second model uses transfer learning models. The fourth model is created based on the group discussion. The fifth model is created based on augmented data and model 3. Among them, model 4 works better compares to the others.\n",
        "\n",
        "The model can help identify patients who are likely to have COVID-19 based on their X-ray images. This can help medical professionals to detect the disease early, which is crucial for successful treatment and preventing the spread of the virus. With the help of machine learning algorithms, the model can quickly and accurately analyze large volumes of X-ray images, reducing the workload of medical professionals and speeding up the diagnosis process. Both the patients and the medical professionals can benefit from the model.\n",
        "\n",
        "Meanwhile, the data collected from the X-ray images can be used for research purposes, helping medical professionals to better understand the disease and develop more effective treatments.\n",
        "\n",
        "Citation of paper providing original dataset:  M.E.H. Chowdhury, T. Rahman, A. Khandakar, R. Mazhar, M.A. Kadir, Z.B. Mahbub, K.R. Islam, M.S. Khan, A. Iqbal, N. Al-Emadi, M.B.I. Reaz, “Can AI help in screening Viral and COVID-19 pneumonia?” arXiv preprint, 29 March 2020, https://arxiv.org/abs/2003.13145"
      ],
      "metadata": {
        "id": "4QwK7WQNH4nE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Predictive Model for Movie Review Classification**\n",
        "\n",
        "**Github link: https://github.com/stellamym/Projects-AdvancedML/blob/main/Predictive%20Model%20for%20Movie%20Review%20Classification.ipynb**\n",
        "\n",
        "Movie review classification is an essential task that helps us understand the opinions and feedback of moviegoers towards different movies. The manual process of reviewing and classifying a vast amount of movie reviews can be time-consuming and impractical. A label prediction model can automate the task of classifying movie reviews, providing consistent and standardized classification while reducing the potential for human error and bias.\n",
        "\n",
        "Building a label prediction model for a movie review classification dataset would be useful for several reasons:\n",
        "\n",
        "* Automation: A label prediction model can automate the task of classifying movie reviews, saving time and effort compared to manual classification. This can be particularly useful when dealing with large datasets that would be impractical to classify manually.\n",
        "\n",
        "* Consistency: A label prediction model can provide consistent and standardized classification, reducing the potential for human error and bias.\n",
        "\n",
        "* Insights: By analyzing the model's predictions, we can gain insights into the factors that contribute to positive or negative reviews. This can help movie studios and filmmakers to better understand their audiences and improve their products.\n",
        "\n",
        "* Recommendation systems: A label prediction model can be integrated into a recommendation system to suggest movies to users based on their preferences. This can improve the user experience and increase user engagement.\n",
        "\n",
        "The dataset I use is called Stanford Sentiment Treebank - Movie Review Classification. In total, there are 8741 reviews, and 6920 labels.\n",
        "\n",
        "There are three seperate datasets in the whole dataset: \n",
        "1. X_train: there are 6920 reviews in X_train.\n",
        "2. X_test: there are 1921 reviews in X_test.\n",
        "3. Y_train_labels: y_train_labels contains 6920 labels of the 6920 reviews in X_train. There are 2 kinds of labels, positive and negative. There are 3610 positive labels and 3310 negative labels.\n",
        "\n",
        "I tried 4 models in total. Model1 uses an Embedding layer and LSTM layers. Model2 uses an Embedding layer and Conv1d layers. Model3 uses transfer learning with glove embeddings. Model4 is created based on Model2 and the discussion results with the group. Among them, Model2 performs the best. The model parameters can be found in the code.\n",
        "\n",
        "The model can be useful for researchers and analysts who are interested in understanding the patterns and trends in movie reviews. They can use the model to identify the most common positive and negative sentiments in the reviews and track how these sentiments change over time.\n",
        "\n",
        "Overall, building a label prediction model for a movie review classification dataset can help to improve efficiency, consistency, and insights, leading to better decision-making and user experiences.\n",
        "\n"
      ],
      "metadata": {
        "id": "6tOYvOKyH4N_"
      }
    }
  ]
}